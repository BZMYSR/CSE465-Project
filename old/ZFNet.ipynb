{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "600f3da2",
   "metadata": {},
   "source": [
    "# CNN Model and Nearest Neighbors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7fda1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb6f530",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Preparing the dataset\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   validation_split=0.2)  # Added validation split\n",
    "\n",
    "# Training and validation sets\n",
    "training_set = train_datagen.flow_from_directory('dataset',\n",
    "                                                 target_size=(224, 224),\n",
    "                                                 batch_size=32,\n",
    "                                                 class_mode='categorical',\n",
    "                                                 subset='training')\n",
    "\n",
    "validation_set = train_datagen.flow_from_directory('dataset',\n",
    "                                                   target_size=(224, 224),\n",
    "                                                   batch_size=32,\n",
    "                                                   class_mode='categorical',\n",
    "                                                   subset='validation')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c50f81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Defining the CNN model\n",
    "# cnn= Sequential([\n",
    "#     Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "#     MaxPooling2D(pool_size=(2, 2)),\n",
    "#     Conv2D(64, (3, 3), activation='relu'),\n",
    "#     MaxPooling2D(pool_size=(2, 2)),\n",
    "#     Conv2D(128, (3, 3), activation='relu'),\n",
    "#     MaxPooling2D(pool_size=(2, 2)),\n",
    "#     Flatten(),\n",
    "#     Dense(128, activation='relu'),\n",
    "#     Dropout(0.5),\n",
    "#     Dense(10, activation='softmax')\n",
    "# ])\n",
    "\n",
    "# # Compiling the model\n",
    "# cnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Training the model\n",
    "# history = cnn.fit(training_set, validation_data=validation_set, epochs=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978d253f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ResNet101 model pre-trained on ImageNet, excluding the fully connected layers (include_top=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "base_model = models.Sequential([\n",
    "        # Layer 1 - Convolutional Layer\n",
    "        layers.Conv2D(96, (7, 7), strides=(2, 2), activation='relu', input_shape=input_shape),\n",
    "        layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2)),\n",
    "        \n",
    "        # Layer 2 - Convolutional Layer\n",
    "        layers.Conv2D(256, (5, 5), activation='relu'),\n",
    "        layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2)),\n",
    "        \n",
    "        # Layer 3 - Convolutional Layer\n",
    "        layers.Conv2D(384, (3, 3), activation='relu'),\n",
    "        \n",
    "        # Layer 4 - Convolutional Layer\n",
    "        layers.Conv2D(384, (3, 3), activation='relu'),\n",
    "        \n",
    "        # Layer 5 - Convolutional Layer\n",
    "        layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2)),\n",
    "        \n",
    "        # Flattening and fully connected layers for classification (you can add any FC layers here)\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(4096, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(4096, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(10, activation='softmax')  # Adjust the number of classes if needed\n",
    "    ])\n",
    "\n",
    "# Freeze the convolutional layers (feature extraction)\n",
    "base_model.trainable = False\n",
    "\n",
    "# Add new fully connected layers for classification\n",
    "new_classifier = Sequential([\n",
    "    GlobalAveragePooling2D(),  # Add a GlobalAveragePooling layer to reduce dimensions\n",
    "    Dense(64, activation='relu'),  # Fully connected layer\n",
    "    Dropout(0.5),  # Dropout for regularization\n",
    "    Dense(10, activation='softmax')  # Output layer (adjust number of classes)\n",
    "])\n",
    "\n",
    "# Combine the ResNet101 base model and the new classifier\n",
    "cnn_model = Sequential([\n",
    "    base_model,  # Add ResNet101 as the base\n",
    "    new_classifier  # Add the new classifier on top\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model on the new dataset (only the fully connected layers will be trained)\n",
    "history = cnn_model.fit(training_set, validation_data=validation_set, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b79417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "# import numpy as np\n",
    "\n",
    "# img = load_img('photos/plan.jpg', target_size=(224, 224))\n",
    "# img_array = img_to_array(img) / 255.0  # Rescale to [0, 1]\n",
    "# img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "\n",
    "# # Perform prediction\n",
    "# predictions = model.predict(img_array)\n",
    "# predicted_class_index = np.argmax(predictions)  # Get the index of the highest probability\n",
    "# class_labels = training_set.class_indices  # Get mapping of class labels to indices\n",
    "# class_labels = {v: k for k, v in class_labels.items()}  # Reverse the dictionary\n",
    "\n",
    "# # Get the class name\n",
    "# predicted_class = class_labels[predicted_class_index]\n",
    "# confidence = predictions[0][predicted_class_index]\n",
    "\n",
    "# print(f\"Predicted class: {predicted_class} with confidence: {confidence:.2f}\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323bebdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "# Function to extract features from ResNet101 base (without the new fully connected layers)\n",
    "def extract_features_fixed(image_path, base_model):\n",
    "    img = load_img(image_path, target_size=(224, 224))  # Load image\n",
    "    img_array = img_to_array(img) / 255.0  # Preprocess the image (normalize)\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "    features = base_model.predict(img_array)  # Extract features from ResNet101 base\n",
    "    return features.flatten()  # Flatten the features to 1D\n",
    "\n",
    "# Function to create feature list for nearest neighbors\n",
    "def create_feature_list(dataset_dir, base_model):\n",
    "    features_list = []\n",
    "    image_paths = []\n",
    "    \n",
    "    for subdir, dirs, files in os.walk(dataset_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(('jpg', 'jpeg', 'png')):\n",
    "                file_path = os.path.join(subdir, file)\n",
    "                features = extract_features_fixed(file_path, base_model)\n",
    "                features_list.append(features)\n",
    "                image_paths.append(file_path)\n",
    "    \n",
    "    return np.array(features_list), image_paths\n",
    "\n",
    "# Create feature list for the whole dataset\n",
    "features_list, image_paths = create_feature_list(\"dataset\", base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d4dccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find the nearest images based on extracted features\n",
    "def find_nearest_images(image_path, base_model, n_neighbors=10):\n",
    "    # Extract features for the input image\n",
    "    image_features = extract_features_fixed(image_path, base_model)\n",
    "    \n",
    "    # Using NearestNeighbors to find the nearest images\n",
    "    neighbors = NearestNeighbors(n_neighbors=n_neighbors, metric='cosine')\n",
    "    neighbors.fit(features_list)\n",
    "    \n",
    "    distances, indices = neighbors.kneighbors([image_features])\n",
    "    \n",
    "    # Print the nearest images and their distance\n",
    "    print(f\"Nearest images to {image_path}:\")\n",
    "    for i in range(n_neighbors):\n",
    "        print(f\"{image_paths[indices[0][i]]} - Distance: {distances[0][i]:.4f}\")\n",
    "    \n",
    "    # Optionally, plot the nearest images\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for i in range(n_neighbors):\n",
    "        img = load_img(image_paths[indices[0][i]], target_size=(224, 224))\n",
    "        plt.subplot(2, 5, i+1)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.title(f\"Distance: {distances[0][i]:.4f}\")\n",
    "    plt.show()\n",
    "\n",
    "# Example usage: Finding nearest images\n",
    "find_nearest_images('vezel.jpg', base_model, n_neighbors=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
